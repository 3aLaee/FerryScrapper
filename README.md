# Python Web Scraper for Price Data Analysis

Welcome to the repository for my internship project at Tanger Med Port Authority! This project is focused on building a Python web scraper that extracts price data from a specified website. The extracted data is then organized and stored in Excel files. Additionally, this tool generates Excel files containing detailed analyses of the collected price data.

## Project Features

- **Web Scraping:** The core functionality of the project involves using selenium to fetch price data from the target website. The scraper is designed to efficiently and reliably extract the required information.

- **Data Storage:** Extracted price data is organized and stored in Excel files. This makes it easy to manage and share the collected data with stakeholders.

- **Data Analysis:** Beyond just collecting data, the project includes functionalities to analyze the extracted price data. Statistical and visual analyses are performed and presented in separate Excel files for easy reference.

## Key Components

1. **Web Scraper:** The scraper module is responsible for navigating the website, extracting price data, and converting it into a structured format.

2. **Data Storage:** Extracted data is stored in Excel files, ensuring data integrity and easy access.

3. **Data Analysis:** Leveraging data analysis libraries, this module generates insightful Excel reports containing statistical summaries, trends, and visualizations.

## How to Use

To use the project:

1. Clone this repository to your local machine.
2. Install the required Python libraries listed in the `requirements.txt` file.
3. Configure the target website's URL and other relevant settings in the scraper module.
4. Run the scraper to fetch price data and store it in Excel files.
5. Run the analysis module to generate Excel files with data analyses.

Feel free to explore the code, customize it to your specific needs, and contribute to the project's development!

## Future Enhancements

While the current version of the project focuses on basic data extraction and analysis, there are several exciting directions for future improvements:

- Implementing more advanced data analysis techniques.
- Enhancing error handling and robustness of the web scraper.
- Adding support for multiple websites and data sources.
- Creating a user-friendly interface for configuration and execution.

## Contributions

If you'd like to contribute, please fork the repository, make your changes, and submit a pull request.

